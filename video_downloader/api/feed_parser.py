"""
Feed JSON è§£æå™¨ - ä¸“é—¨å¤„ç†feed.jsonæ ¼å¼çš„æ•°æ®
ä»feed.jsonä¸­æå–IDåˆ—è¡¨ï¼Œç„¶åæ‰¹é‡è¯·æ±‚è¯¦ç»†æ•°æ®
"""

import json
import time
import requests
import urllib3
from typing import List, Dict, Any, Optional
from datetime import datetime

from ..core.config import Config
from ..database.models import VideoRecord

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class FeedParser:
    """Feed JSONè§£æå™¨"""

    def __init__(self):
        self.config = Config()
        # åˆ›å»ºä¼šè¯ï¼Œç¦ç”¨ä»£ç†
        self.session = requests.Session()
        self.session.trust_env = False
        self.session.proxies = {}

        # è¯·æ±‚è®¾ç½®
        self.request_delay = 2.0  # è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        self.max_retries = 3     # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.timeout = 30        # è¯·æ±‚è¶…æ—¶æ—¶é—´

    def parse_feed_file(self, file_path: str) -> List[str]:
        """
        è§£æfeed.jsonæ–‡ä»¶ï¼Œæå–æ‰€æœ‰è§†é¢‘ID

        Args:
            file_path (str): feed.jsonæ–‡ä»¶è·¯å¾„

        Returns:
            List[str]: è§†é¢‘IDåˆ—è¡¨
        """
        try:
            print(f"ğŸ“– æ­£åœ¨è¯»å–feedæ–‡ä»¶: {file_path}")

            with open(file_path, 'r', encoding='utf-8') as f:
                feed_data = json.load(f)

            # éªŒè¯æ•°æ®æ ¼å¼
            if not isinstance(feed_data, dict):
                raise ValueError("Feedæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šæœŸæœ›JSONå¯¹è±¡")

            items = feed_data.get('items', [])
            if not isinstance(items, list):
                raise ValueError("Feedæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šitemså­—æ®µåº”ä¸ºæ•°ç»„")

            # æå–IDåˆ—è¡¨
            id_list = []
            for i, item in enumerate(items):
                if isinstance(item, dict) and 'id' in item:
                    video_id = item['id']
                    if video_id and isinstance(video_id, str):
                        id_list.append(video_id)
                        print(f"âœ… æå–ID {i+1}: {video_id}")
                    else:
                        print(f"âš ï¸ è·³è¿‡æ— æ•ˆID (ç¬¬{i+1}é¡¹): {video_id}")
                else:
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆé¡¹ç›® (ç¬¬{i+1}é¡¹): ç¼ºå°‘IDå­—æ®µ")

            print(f"ğŸ¯ æˆåŠŸæå– {len(id_list)} ä¸ªè§†é¢‘ID")

            # æ˜¾ç¤ºfeedæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
            total = feed_data.get('total', 'N/A')
            page = feed_data.get('page', 'N/A')
            size = feed_data.get('size', 'N/A')
            pages = feed_data.get('pages', 'N/A')
            print(f"ğŸ“Š Feedä¿¡æ¯ - æ€»è®°å½•: {total}, å½“å‰é¡µ: {page}, é¡µé¢å¤§å°: {size}, æ€»é¡µæ•°: {pages}")

            return id_list

        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return []
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            return []
        except Exception as e:
            print(f"âŒ è§£æfeedæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def fetch_video_details(self, video_id: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®è§†é¢‘IDè·å–è¯¦ç»†ä¿¡æ¯

        Args:
            video_id (str): è§†é¢‘ID

        Returns:
            Optional[Dict[str, Any]]: è§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        url = f"https://api.memefans.ai/v2/posts/videos/{video_id}"
        headers = self.config.DEFAULT_HEADERS

        for attempt in range(self.max_retries):
            try:
                if attempt > 0:
                    delay = self.request_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                    print(f"â³ ç¬¬ {attempt} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)

                print(f"ğŸ”„ è¯·æ±‚è§†é¢‘è¯¦æƒ…: {video_id} (å°è¯• {attempt + 1}/{self.max_retries})")

                response = self.session.get(
                    url,
                    headers=headers,
                    verify=False,
                    timeout=self.timeout
                )

                response.raise_for_status()

                video_data = response.json()
                print(f"âœ… æˆåŠŸè·å–è§†é¢‘è¯¦æƒ…: {video_id}")

                return video_data

            except requests.exceptions.RequestException as e:
                print(f"âŒ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                if attempt == self.max_retries - 1:
                    print(f"ğŸ’¥ æœ€ç»ˆå¤±è´¥ï¼Œè·³è¿‡è§†é¢‘ID: {video_id}")
                    return None
            except json.JSONDecodeError as e:
                print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                return None
            except Exception as e:
                print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
                return None

        return None

    def process_video_data(self, video_data: Dict[str, Any]) -> Optional[VideoRecord]:
        """
        å°†è·å–åˆ°çš„è§†é¢‘è¯¦æƒ…è½¬æ¢ä¸ºVideoRecordå¯¹è±¡

        Args:
            video_data (Dict[str, Any]): è§†é¢‘è¯¦ç»†æ•°æ®

        Returns:
            Optional[VideoRecord]: VideoRecordå¯¹è±¡ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            # ä½¿ç”¨ç°æœ‰çš„VideoRecord.from_api_dataæ–¹æ³•
            video_record = VideoRecord.from_api_data(video_data)
            return video_record

        except Exception as e:
            print(f"âŒ è½¬æ¢VideoRecordå¤±è´¥: {e}")
            print(f"   æ•°æ®å†…å®¹: {str(video_data)[:200]}...")
            return None

    def batch_process_feed(self, file_path: str) -> List[VideoRecord]:
        """
        æ‰¹é‡å¤„ç†feedæ–‡ä»¶ï¼šæå–ID -> è¯·æ±‚è¯¦æƒ… -> è½¬æ¢ä¸ºVideoRecord

        Args:
            file_path (str): feed.jsonæ–‡ä»¶è·¯å¾„

        Returns:
            List[VideoRecord]: æˆåŠŸè§£æçš„VideoRecordåˆ—è¡¨
        """
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†feedæ–‡ä»¶: {file_path}")

        # 1. æå–IDåˆ—è¡¨
        id_list = self.parse_feed_file(file_path)
        if not id_list:
            print("âŒ æœªèƒ½æå–åˆ°æœ‰æ•ˆçš„è§†é¢‘ID")
            return []

        # 2. æ‰¹é‡è¯·æ±‚è§†é¢‘è¯¦æƒ…å¹¶è½¬æ¢
        video_records = []
        failed_count = 0

        total_ids = len(id_list)
        print(f"ğŸ“¦ å¼€å§‹æ‰¹é‡è¯·æ±‚ {total_ids} ä¸ªè§†é¢‘çš„è¯¦ç»†ä¿¡æ¯...")

        for i, video_id in enumerate(id_list):
            print(f"\nğŸ“¹ å¤„ç†è§†é¢‘ {i+1}/{total_ids}: {video_id}")

            # è¯·æ±‚è§†é¢‘è¯¦æƒ…
            video_data = self.fetch_video_details(video_id)
            if not video_data:
                failed_count += 1
                continue

            # è½¬æ¢ä¸ºVideoRecord
            video_record = self.process_video_data(video_data)
            if video_record:
                video_records.append(video_record)
                print(f"âœ… æˆåŠŸå¤„ç†: {video_record.title} ({video_record.video_date})")
            else:
                failed_count += 1

            # è¯·æ±‚é—´éš”ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
            if i < total_ids - 1:  # æœ€åä¸€ä¸ªè¯·æ±‚ä¸éœ€è¦ç­‰å¾…
                print(f"â³ ç­‰å¾… {self.request_delay} ç§’åç»§ç»­...")
                time.sleep(self.request_delay)

        # æ±‡æ€»ç»“æœ
        success_count = len(video_records)
        print(f"\nğŸ¯ æ‰¹é‡å¤„ç†å®Œæˆ!")
        print(f"   æ€»è®¡: {total_ids} ä¸ªID")
        print(f"   æˆåŠŸ: {success_count} ä¸ª")
        print(f"   å¤±è´¥: {failed_count} ä¸ª")
        print(f"   æˆåŠŸç‡: {success_count/total_ids*100:.1f}%")

        return video_records

    def save_cache_file(self, video_records: List[VideoRecord], cache_file_path: str):
        """
        å°†å¤„ç†ç»“æœä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶

        Args:
            video_records (List[VideoRecord]): è§†é¢‘è®°å½•åˆ—è¡¨
            cache_file_path (str): ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        try:
            cache_data = []
            for record in video_records:
                cache_data.append({
                    'title': record.title,
                    'video_date': record.video_date,
                    'cover': record.cover,
                    'url': record.url,
                    'description': record.description,
                    'uid': record.uid,
                    'download': record.download,
                    'is_primer': record.is_primer,
                    'created_at': record.created_at.isoformat() if record.created_at else None,
                    'updated_at': record.updated_at.isoformat() if record.updated_at else None
                })

            with open(cache_file_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ç¼“å­˜æ–‡ä»¶å·²ä¿å­˜: {cache_file_path}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
