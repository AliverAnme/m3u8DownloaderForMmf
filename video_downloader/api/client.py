"""
APIç›¸å…³åŠŸèƒ½æ¨¡å—
å¤„ç†APIæ•°æ®è·å–ã€è§£æå’Œä¿å­˜
"""

import requests
import json
import urllib3
import re
from typing import Dict, Any, List

from ..core.config import Config

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class APIClient:

    def __init__(self):
        self.config = Config()

    def fetch_posts_from_api(self, size: int = 50, verify_ssl: bool = False) -> Dict[str, Any]:
        """
        ä»APIæ¥å£è·å–postsæ•°æ®å¹¶ä¿å­˜åˆ°æœ¬åœ°

        Args:
            size (int): æ¯é¡µè¿”å›çš„æ•°æ®æ¡æ•°ï¼Œé»˜è®¤ä¸º50
            verify_ssl (bool): æ˜¯å¦éªŒè¯SSLè¯ä¹¦ï¼Œé»˜è®¤ä¸ºFalse

        Returns:
            Dict[str, Any]: APIè¿”å›çš„JSONæ•°æ®
        """
        # APIæ¥å£URL
        base_url = self.config.API_BASE_URL

        # å›ºå®šå‚æ•°
        params = {
            "author_id": self.config.DEFAULT_AUTHOR_ID,
            "page": 1,
            "size": size
        }

        # è®¾ç½®è¯·æ±‚å¤´
        headers = self.config.DEFAULT_HEADERS

        try:
            print(f"æ­£åœ¨è¯·æ±‚API: {base_url}")
            print(f"å‚æ•°: {params}")
            print(f"SSLéªŒè¯: {'å¯ç”¨' if verify_ssl else 'ç¦ç”¨'}")

            # å‘é€GETè¯·æ±‚ï¼Œç¦ç”¨SSLéªŒè¯å¹¶è®¾ç½®è¶…æ—¶
            response = requests.get(
                base_url,
                params=params,
                headers=headers,
                verify=verify_ssl,
                timeout=self.config.API_TIMEOUT
            )
            response.raise_for_status()

            # è§£æJSONæ•°æ®
            data = response.json()

            # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
            output_file = self.config.API_RESPONSE_FILE
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {output_file}")
            print(f"è·å–åˆ° {len(data.get('items', []))} æ¡è®°å½•")

            return data

        except requests.exceptions.SSLError as e:
            print(f"SSLé”™è¯¯: {e}")
            print("å°è¯•ç¦ç”¨SSLéªŒè¯é‡æ–°è¯·æ±‚...")
            if verify_ssl:
                return self.fetch_posts_from_api(size, verify_ssl=False)
            else:
                print("SSLéªŒè¯å·²ç¦ç”¨ï¼Œä½†ä»ç„¶å‡ºç°SSLé”™è¯¯")
                return {}
        except requests.exceptions.RequestException as e:
            print(f"APIè¯·æ±‚å¤±è´¥: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            return {}
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            print("å“åº”å†…å®¹å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
            return {}
        except Exception as e:
            print(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            return {}

    def extract_title_from_description(self, description: str) -> str:
        """
        ä»descriptionä¸­æå–æ ‡é¢˜å†…å®¹ï¼ˆä¸DataProcessorä¿æŒä¸€è‡´ï¼‰

        Args:
            description (str): å®Œæ•´çš„æè¿°æ–‡æœ¬

        Returns:
            str: æå–çš„æ ‡é¢˜
        """
        if not description:
            return ""

        # æ–¹æ³•1: æå–ã€ã€‘å¼€å¤´åˆ°ç¬¬ä¸€ä¸ª # æˆ–è€…ç‰¹å®šå…³é”®è¯ä¹‹å‰çš„å†…å®¹
        pattern1 = r'ã€[^ã€‘]+ã€‘([^#]+?)(?:\s*#|\s*$)'
        match1 = re.search(pattern1, description)
        if match1:
            title = match1.group(0).strip()
            title = re.sub(r'\s*#.*$', '', title).strip()
            return title

        # æ–¹æ³•2: å¦‚æœæ²¡æœ‰ã€ã€‘æ ¼å¼ï¼Œæå–ç¬¬ä¸€ä¸ª#ä¹‹å‰çš„å†…å®¹
        pattern2 = r'^([^#]+?)(?:\s*#|$)'
        match2 = re.search(pattern2, description)
        if match2:
            title = match2.group(1).strip()
            return title

        # æ–¹æ³•3: å¦‚æœéƒ½æ²¡æœ‰åŒ¹é…ï¼Œè¿”å›å‰100ä¸ªå­—ç¬¦
        return description[:100] + "..." if len(description) > 100 else description

    def process_posts_data(self, data: Dict[str, Any]) -> None:
        """
        å¤„ç†ä»APIè·å–çš„postsæ•°æ®

        Args:
            data (Dict[str, Any]): APIè¿”å›çš„æ•°æ®
        """
        if not data or 'items' not in data:
            print("æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
            return

        items = data['items']
        total = data.get('total', 0)
        page = data.get('page', 1)
        size = data.get('size', 50)

        print(f"\næ•°æ®æ¦‚è§ˆ:")
        print(f"æ€»è®°å½•æ•°: {total}")
        print(f"å½“å‰é¡µ: {page}")
        print(f"æ¯é¡µå¤§å°: {size}")
        print(f"å½“å‰é¡µè®°å½•æ•°: {len(items)}")

        print(f"\nå‰3æ¡è®°å½•çš„æ ‡é¢˜:")
        for i, item in enumerate(items[:3], 1):
            # ä½¿ç”¨ä¸å…¶ä»–æ¨¡å¼ä¸€è‡´çš„æ ‡é¢˜æå–æ–¹æ³•
            description = item.get('description', '')
            title = self.extract_title_from_description(description)
            if not title:
                title = item.get('title', 'No title')

            likes = item.get('likes_count', 0)
            comments = item.get('comments_count', 0)
            print(f"{i}. {title} (ğŸ‘{likes} ğŸ’¬{comments})")
