"""
å¢å¼ºJSONè§£æå™¨ - ä¸“é—¨å¤„ç†å¤æ‚çš„APIè¿”å›æ•°æ®
æ”¯æŒå­—ç¬¦ä¸²å¯¹è±¡è¡¨ç¤ºã€åµŒå¥—JSONå­—ç¬¦ä¸²ã€æ··åˆæ•°æ®æ ¼å¼ç­‰
"""

import json
import re
import ast
from typing import Dict, Any, List, Optional, Union
from datetime import datetime


class EnhancedJSONParser:
    """å¢å¼ºçš„JSONè§£æå™¨ï¼Œæ”¯æŒå¤šç§æ•°æ®æ ¼å¼"""

    def __init__(self):
        self.parse_stats = {
            'total_items': 0,
            'successful_parses': 0,
            'string_object_parses': 0,
            'json_string_parses': 0,
            'fallback_parses': 0,
            'failed_parses': 0
        }

    def parse_api_response(self, data: Union[str, Dict, Any]) -> Dict[str, Any]:
        """
        è§£æAPIå“åº”æ•°æ®ï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼

        Args:
            data: APIå“åº”æ•°æ®ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²ã€å­—å…¸æˆ–å…¶ä»–æ ¼å¼ï¼‰

        Returns:
            Dict[str, Any]: æ ‡å‡†åŒ–çš„JSONæ•°æ®
        """
        try:
            # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
            self.parse_stats = {k: 0 for k in self.parse_stats}

            print("ğŸ” å¼€å§‹è§£æAPIå“åº”æ•°æ®...")

            # 1. å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
            if isinstance(data, str):
                parsed_data = self._parse_string_data(data)
            # 2. å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
            elif isinstance(data, dict):
                parsed_data = data
            # 3. å¦‚æœæ˜¯åˆ—è¡¨ï¼ŒåŒ…è£…ä¸ºæ ‡å‡†æ ¼å¼
            elif isinstance(data, list):
                parsed_data = {'items': data}
            # 4. å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢
            else:
                parsed_data = self._parse_unknown_type(data)

            # éªŒè¯å’Œæ ‡å‡†åŒ–æ•°æ®ç»“æ„
            if isinstance(parsed_data, dict) and 'items' in parsed_data:
                parsed_data['items'] = self._parse_items_array(parsed_data['items'])

            # è¾“å‡ºè§£æç»Ÿè®¡
            self._print_parse_stats()

            return parsed_data

        except Exception as e:
            print(f"âŒ APIå“åº”è§£æå¤±è´¥: {e}")
            return {'items': [], 'error': str(e)}

    def _parse_string_data(self, data: str) -> Dict[str, Any]:
        """è§£æå­—ç¬¦ä¸²æ•°æ®"""
        data = data.strip()

        # å°è¯•ç›´æ¥JSONè§£æ
        try:
            return json.loads(data)
        except json.JSONDecodeError:
            pass

        # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹è±¡è¡¨ç¤ºå­—ç¬¦ä¸²
        if self._is_object_representation(data):
            return self._parse_object_string(data)

        # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
        fixed_data = self._fix_json_format(data)
        try:
            return json.loads(fixed_data)
        except json.JSONDecodeError:
            pass

        # æœ€åå°è¯•æå–JSONç‰‡æ®µ
        return self._extract_json_fragments(data)

    def _parse_items_array(self, items: List[Any]) -> List[Dict[str, Any]]:
        """è§£æitemsæ•°ç»„ï¼Œå¤„ç†å„ç§æ ¼å¼çš„item"""
        if not isinstance(items, list):
            print(f"âš ï¸ itemsä¸æ˜¯åˆ—è¡¨æ ¼å¼: {type(items)}")
            return []

        parsed_items = []
        self.parse_stats['total_items'] = len(items)

        for i, item in enumerate(items):
            try:
                parsed_item = self._parse_single_item(item, i)
                if parsed_item:
                    parsed_items.append(parsed_item)
                    self.parse_stats['successful_parses'] += 1
                else:
                    self.parse_stats['failed_parses'] += 1
            except Exception as e:
                print(f"âŒ è§£æç¬¬{i+1}é¡¹å¤±è´¥: {e}")
                self.parse_stats['failed_parses'] += 1

        return parsed_items

    def _parse_single_item(self, item: Any, index: int) -> Optional[Dict[str, Any]]:
        """è§£æå•ä¸ªæ•°æ®é¡¹"""
        # 1. å­—å…¸æ ¼å¼ - æ ‡å‡†æƒ…å†µ
        if isinstance(item, dict):
            return self._normalize_dict_item(item)

        # 2. å­—ç¬¦ä¸²æ ¼å¼ - å¯èƒ½æ˜¯JSONå­—ç¬¦ä¸²æˆ–å¯¹è±¡è¡¨ç¤º
        elif isinstance(item, str):
            return self._parse_string_item(item, index)

        # 3. å¯¹è±¡æ ¼å¼ - æœ‰__dict__å±æ€§çš„å¯¹è±¡
        elif hasattr(item, '__dict__'):
            return self._parse_object_item(item)

        # 4. åˆ—è¡¨æ ¼å¼ - åµŒå¥—åˆ—è¡¨
        elif isinstance(item, list):
            return self._parse_list_item(item, index)

        # 5. å…¶ä»–æ ¼å¼
        else:
            return self._parse_other_item(item, index)

    def _parse_string_item(self, item: str, index: int) -> Optional[Dict[str, Any]]:
        """è§£æå­—ç¬¦ä¸²æ ¼å¼çš„item"""
        item = item.strip()

        # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹è±¡è¡¨ç¤º
        if self._is_object_representation(item):
            self.parse_stats['string_object_parses'] += 1
            return self._parse_object_string(item)

        # å°è¯•JSONè§£æ
        try:
            parsed = json.loads(item)
            if isinstance(parsed, dict):
                self.parse_stats['json_string_parses'] += 1
                return self._normalize_dict_item(parsed)
        except json.JSONDecodeError:
            pass

        # å°è¯•ä¿®å¤JSONæ ¼å¼
        fixed_item = self._fix_json_format(item)
        try:
            parsed = json.loads(fixed_item)
            if isinstance(parsed, dict):
                self.parse_stats['json_string_parses'] += 1
                return self._normalize_dict_item(parsed)
        except json.JSONDecodeError:
            pass

        # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–ä¿¡æ¯
        return self._extract_from_string(item, index)

    def _is_object_representation(self, text: str) -> bool:
        """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦æ˜¯å¯¹è±¡è¡¨ç¤º"""
        patterns = [
            r'<.*?object\s+at\s+0x[0-9a-f]+>',  # <Video object at 0x...>
            r'<.*?\s+object\s+at\s+0x[0-9a-f]+>',  # <SomeClass object at 0x...>
            r'Video\([^)]*\)',  # Video(id=123, title="...")
            r'\w+\([^)]*\)',  # ClassName(field=value, ...)
        ]

        for pattern in patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True

        return False

    def _parse_object_string(self, obj_str: str) -> Dict[str, Any]:
        """è§£æå¯¹è±¡è¡¨ç¤ºå­—ç¬¦ä¸²"""
        result = {'_source': 'object_string', '_raw': obj_str}

        # å°è¯•æå–ç±»å
        class_match = re.search(r'<(\w+)\s+object', obj_str, re.IGNORECASE)
        if class_match:
            result['_class'] = class_match.group(1)

        # å°è¯•æå–æ‹¬å·å†…çš„å‚æ•°
        param_match = re.search(r'\(([^)]+)\)', obj_str)
        if param_match:
            params_str = param_match.group(1)
            result.update(self._parse_object_parameters(params_str))

        # å°è¯•æå–å¸¸è§å­—æ®µ
        self._extract_common_fields(obj_str, result)

        return result

    def _parse_object_parameters(self, params_str: str) -> Dict[str, Any]:
        """è§£æå¯¹è±¡å‚æ•°å­—ç¬¦ä¸²"""
        params = {}

        # åˆ†å‰²å‚æ•°ï¼ˆè€ƒè™‘åµŒå¥—å¼•å·ï¼‰
        param_items = self._split_parameters(params_str)

        for item in param_items:
            if '=' in item:
                key, value = item.split('=', 1)
                key = key.strip()
                value = value.strip()

                # å°è¯•è§£æå€¼
                params[key] = self._parse_parameter_value(value)

        return params

    def _split_parameters(self, params_str: str) -> List[str]:
        """æ™ºèƒ½åˆ†å‰²å‚æ•°å­—ç¬¦ä¸²"""
        items = []
        current = ""
        in_quotes = False
        quote_char = None
        paren_level = 0

        for char in params_str:
            if char in '"\'':
                if not in_quotes:
                    in_quotes = True
                    quote_char = char
                elif char == quote_char:
                    in_quotes = False
                    quote_char = None
            elif char == '(' and not in_quotes:
                paren_level += 1
            elif char == ')' and not in_quotes:
                paren_level -= 1
            elif char == ',' and not in_quotes and paren_level == 0:
                items.append(current.strip())
                current = ""
                continue

            current += char

        if current.strip():
            items.append(current.strip())

        return items

    def _parse_parameter_value(self, value: str) -> Any:
        """è§£æå‚æ•°å€¼"""
        value = value.strip()

        # ç§»é™¤å¤–å±‚å¼•å·
        if (value.startswith('"') and value.endswith('"')) or \
           (value.startswith("'") and value.endswith("'")):
            return value[1:-1]

        # å°è¯•è§£æä¸ºæ•°å­—
        try:
            if '.' in value:
                return float(value)
            else:
                return int(value)
        except ValueError:
            pass

        # å°è¯•è§£æä¸ºå¸ƒå°”å€¼
        if value.lower() in ('true', 'false'):
            return value.lower() == 'true'

        # å°è¯•è§£æä¸ºNone
        if value.lower() in ('none', 'null'):
            return None

        # å°è¯•è§£æä¸ºåˆ—è¡¨æˆ–å­—å…¸
        try:
            return ast.literal_eval(value)
        except (ValueError, SyntaxError):
            pass

        # è¿”å›åŸå§‹å­—ç¬¦ä¸²
        return value

    def _extract_common_fields(self, text: str, result: Dict[str, Any]):
        """ä»æ–‡æœ¬ä¸­æå–å¸¸è§å­—æ®µ"""
        # æå–å¸¸è§çš„å­—æ®µæ¨¡å¼
        patterns = {
            'id': r'id[\'"]?\s*[:=]\s*[\'"]?([^,\'")\s]+)',
            'title': r'title[\'"]?\s*[:=]\s*[\'"]([^\'"]+)',
            'description': r'description[\'"]?\s*[:=]\s*[\'"]([^\'"]]*)',
            'url': r'url[\'"]?\s*[:=]\s*[\'"]([^\'"\s]+)',
            'cover': r'cover[\'"]?\s*[:=]\s*[\'"]([^\'"\s]+)',
        }

        for field, pattern in patterns.items():
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                result[field] = match.group(1)

    def _normalize_dict_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–å­—å…¸æ ¼å¼çš„item"""
        # å¤„ç†åµŒå¥—çš„JSONå­—ç¬¦ä¸²
        normalized = {}
        for key, value in item.items():
            if isinstance(value, str) and self._looks_like_json(value):
                try:
                    normalized[key] = json.loads(value)
                except json.JSONDecodeError:
                    normalized[key] = value
            else:
                normalized[key] = value

        return normalized

    def _looks_like_json(self, text: str) -> bool:
        """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦åƒJSONæ ¼å¼"""
        text = text.strip()
        return (text.startswith('{') and text.endswith('}')) or \
               (text.startswith('[') and text.endswith(']'))

    def _fix_json_format(self, text: str) -> str:
        """ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜"""
        # ç§»é™¤BOM
        if text.startswith('\ufeff'):
            text = text[1:]

        # ä¿®å¤å•å¼•å·ä¸ºåŒå¼•å·
        text = re.sub(r"'([^']*)':", r'"\1":', text)
        text = re.sub(r":\s*'([^']*)'", r': "\1"', text)

        # ä¿®å¤å°¾éšé€—å·
        text = re.sub(r',\s*}', '}', text)
        text = re.sub(r',\s*]', ']', text)

        # ä¿®å¤æœªå¼•ç”¨çš„é”®
        text = re.sub(r'(\w+):', r'"\1":', text)

        return text

    def _extract_json_fragments(self, text: str) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­æå–JSONç‰‡æ®µ"""
        result = {'items': [], '_source': 'text_extraction'}

        # æŸ¥æ‰¾JSONå¯¹è±¡
        json_objects = re.findall(r'\{[^{}]*}', text)
        for obj_str in json_objects:
            try:
                obj = json.loads(obj_str)
                if isinstance(obj, dict):
                    result['items'].append(obj)
            except json.JSONDecodeError:
                continue

        # æŸ¥æ‰¾JSONæ•°ç»„
        json_arrays = re.findall(r'\[[^\[\]]*]', text)
        for arr_str in json_arrays:
            try:
                arr = json.loads(arr_str)
                if isinstance(arr, list):
                    result['items'].extend(arr)
            except json.JSONDecodeError:
                continue

        return result

    def _extract_from_string(self, text: str, index: int) -> Optional[Dict[str, Any]]:
        """ä»æ™®é€šå­—ç¬¦ä¸²ä¸­æå–ä¿¡æ¯"""
        self.parse_stats['fallback_parses'] += 1

        result = {
            '_source': 'string_extraction',
            '_index': index,
            'raw_text': text[:200] + ('...' if len(text) > 200 else '')
        }

        # å°è¯•æå–URL
        url_pattern = r'https?://[^\s<>"\']+[^\s<>"\'.,;]'
        urls = re.findall(url_pattern, text)
        if urls:
            result['url'] = urls[0]

        # å°è¯•æå–ID
        id_pattern = r'\b[A-Za-z0-9]{10,}\b'
        ids = re.findall(id_pattern, text)
        if ids:
            result['id'] = ids[0]

        # ä½¿ç”¨æ–‡æœ¬ä½œä¸ºæè¿°
        if len(text) > 10:
            result['description'] = text

        return result if len(result) > 3 else None

    def _parse_object_item(self, obj: Any) -> Dict[str, Any]:
        """è§£æå¯¹è±¡æ ¼å¼çš„item"""
        result = {'_source': 'object'}

        # è·å–å¯¹è±¡å±æ€§
        if hasattr(obj, '__dict__'):
            result.update(obj.__dict__)

        # å°è¯•è·å–å¸¸è§å±æ€§
        common_attrs = ['id', 'title', 'description', 'url', 'cover', 'author', 'date']
        for attr in common_attrs:
            if hasattr(obj, attr):
                result[attr] = getattr(obj, attr)

        return result

    def _parse_list_item(self, item: List[Any], index: int) -> Optional[Dict[str, Any]]:
        """è§£æåˆ—è¡¨æ ¼å¼çš„item"""
        if not item:
            return None

        result = {
            '_source': 'list',
            '_index': index,
            'items': item
        }

        # å¦‚æœåˆ—è¡¨åªæœ‰ä¸€ä¸ªå…ƒç´ ï¼Œå°è¯•è§£æå®ƒ
        if len(item) == 1:
            return self._parse_single_item(item[0], index)

        return result

    def _parse_other_item(self, item: Any, index: int) -> Optional[Dict[str, Any]]:
        """è§£æå…¶ä»–æ ¼å¼çš„item"""
        result = {
            '_source': 'other',
            '_index': index,
            '_type': type(item).__name__,
            'value': str(item)
        }

        return result

    def _parse_unknown_type(self, data: Any) -> Dict[str, Any]:
        """è§£ææœªçŸ¥ç±»å‹çš„æ•°æ®"""
        result = {'_source': 'unknown_type', '_type': type(data).__name__}

        # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶è§£æ
        try:
            str_data = str(data)
            if str_data:
                result.update(self._parse_string_data(str_data))
        except Exception:
            result['error'] = 'Failed to convert to string'

        return result

    def _print_parse_stats(self):
        """è¾“å‡ºè§£æç»Ÿè®¡ä¿¡æ¯"""
        stats = self.parse_stats
        print(f"ğŸ“Š è§£æç»Ÿè®¡ - æ€»è®¡: {stats['total_items']}, "
              f"æˆåŠŸ: {stats['successful_parses']}, "
              f"å¯¹è±¡å­—ç¬¦ä¸²: {stats['string_object_parses']}, "
              f"JSONå­—ç¬¦ä¸²: {stats['json_string_parses']}, "
              f"å›é€€è§£æ: {stats['fallback_parses']}, "
              f"å¤±è´¥: {stats['failed_parses']}")

    def parse_json_string(self, json_str: str) -> Dict[str, Any]:
        """
        è§£æJSONå­—ç¬¦ä¸²

        Args:
            json_str (str): JSONå­—ç¬¦ä¸²

        Returns:
            Dict[str, Any]: è§£æåçš„å­—å…¸
        """
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            # å°è¯•ä¿®å¤æ ¼å¼åå†è§£æ
            fixed_str = self._fix_json_format(json_str)
            try:
                return json.loads(fixed_str)
            except json.JSONDecodeError:
                return {'error': 'Invalid JSON format', 'raw': json_str}

    def extract_video_info(self, content: str) -> Optional[Dict[str, Any]]:
        """
        ä»å†…å®¹ä¸­æå–è§†é¢‘ä¿¡æ¯

        Args:
            content (str): å†…å®¹æ–‡æœ¬

        Returns:
            Optional[Dict[str, Any]]: æå–çš„è§†é¢‘ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆä¿¡æ¯åˆ™è¿”å›None
        """
        if not content or not isinstance(content, str):
            return None

        content = content.strip()
        if not content:
            return None

        video_info = {}

        # æå–æ ‡é¢˜
        title = self._extract_title(content)
        if title:
            video_info['title'] = title

        # æå–è§†é¢‘URL
        video_url = self._extract_video_url(content)
        if video_url:
            video_info['video_url'] = video_url

        # æå–å°é¢URL
        cover_url = self._extract_cover_url(content)
        if cover_url:
            video_info['cover_url'] = cover_url

        # æå–ä½œè€…
        author = self._extract_author(content)
        if author:
            video_info['author'] = author

        # æå–æ—¥æœŸ
        video_date = self._extract_date(content)
        if video_date:
            video_info['video_date'] = video_date
        else:
            video_info['video_date'] = datetime.now().strftime('%Y-%m-%d')

        # æå–æ ‡ç­¾
        tags = self._extract_tags(content)
        if tags:
            video_info['tags'] = tags

        # æå–æ—¶é•¿
        duration = self._extract_duration(content)
        if duration:
            video_info['duration'] = duration

        # æå–æ–‡ä»¶å¤§å°
        file_size = self._extract_file_size(content)
        if file_size:
            video_info['file_size'] = file_size

        # æå–åˆ†è¾¨ç‡
        resolution = self._extract_resolution(content)
        if resolution:
            video_info['resolution'] = resolution

        # å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼Œä½¿ç”¨å†…å®¹çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
        if not video_info.get('title'):
            if len(content) > 50:
                video_info['title'] = content[:50] + '...'
            else:
                video_info['title'] = content

        # åªæœ‰å½“è‡³å°‘æœ‰æ ‡é¢˜æ—¶æ‰è¿”å›ç»“æœ
        if video_info.get('title'):
            return video_info

        return None

    def _extract_title(self, content: str) -> Optional[str]:
        """æå–æ ‡é¢˜"""
        # å°è¯•å¤šç§æ ‡é¢˜æ¨¡å¼
        title_patterns = [
            r'title[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'æ ‡é¢˜[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'<title>([^<]+)</title>',
            r'ã€([^ã€‘]+)ã€‘',
            r'ã€Š([^ã€‹]+)ã€‹',
            r'^([^ã€‚ï¼ï¼Ÿ\n]{5,50})',  # å¼€å¤´çš„çŸ­å¥ä½œä¸ºæ ‡é¢˜
        ]

        for pattern in title_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                title = match.group(1).strip()
                if len(title) > 3:
                    return title

        return None

    def _extract_video_url(self, content: str) -> Optional[str]:
        """æå–è§†é¢‘URL"""
        # è§†é¢‘URLæ¨¡å¼
        video_patterns = [
            r'https?://[^\s<>"\']+\.(?:mp4|avi|mov|mkv|flv|wmv|webm|m4v)',
            r'video_url[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'videoUrl[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'url[\'"]?\s*[:=]\s*[\'"]([^\'"\s]+\.(?:mp4|avi|mov|mkv|flv|wmv|webm|m4v))[\'"]',
        ]

        for pattern in video_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                url = match.group(1) if match.groups() else match.group(0)
                if url and url.startswith('http'):
                    return url

        return None

    def _extract_cover_url(self, content: str) -> Optional[str]:
        """æå–å°é¢URL"""
        # å°é¢URLæ¨¡å¼
        cover_patterns = [
            r'https?://[^\s<>"\']+\.(?:jpg|jpeg|png|gif|bmp|webp)',
            r'cover[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'coverUrl[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'thumbnail[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'poster[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
        ]

        for pattern in cover_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                url = match.group(1) if match.groups() else match.group(0)
                if url and url.startswith('http'):
                    return url

        return None

    def _extract_author(self, content: str) -> Optional[str]:
        """æå–ä½œè€…"""
        author_patterns = [
            r'author[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'creator[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'uploader[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'ä½œè€…[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'UPä¸»[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'@(\w+)',
        ]

        for pattern in author_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                author = match.group(1).strip()
                if len(author) > 1:
                    return author

        return None

    def _extract_date(self, content: str) -> Optional[str]:
        """æå–æ—¥æœŸ"""
        date_patterns = [
            r'date[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'created[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'published[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'æ—¶é—´[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
            r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
        ]

        for pattern in date_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                date_str = match.group(1).strip()
                if len(date_str) > 5:
                    return date_str

        return None

    def _extract_tags(self, content: str) -> Optional[str]:
        """æå–æ ‡ç­¾"""
        tag_patterns = [
            r'tags[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'keywords[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'æ ‡ç­¾[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'#(\w+)',
        ]

        tags = []
        for pattern in tag_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            tags.extend(matches)

        if tags:
            return ', '.join(set(tags))

        return None

    def _extract_duration(self, content: str) -> Optional[str]:
        """æå–æ—¶é•¿"""
        duration_patterns = [
            r'duration[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'length[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'æ—¶é•¿[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'(\d{1,2}:\d{2}:\d{2})',
            r'(\d{1,2}:\d{2})',
        ]

        for pattern in duration_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                duration = match.group(1).strip()
                if ':' in duration or duration.isdigit():
                    return duration

        return None

    def _extract_file_size(self, content: str) -> Optional[str]:
        """æå–æ–‡ä»¶å¤§å°"""
        size_patterns = [
            r'size[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'filesize[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'å¤§å°[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'(\d+\.?\d*\s*[KMGT]B)',
        ]

        for pattern in size_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                size = match.group(1).strip()
                if any(unit in size.upper() for unit in ['B', 'KB', 'MB', 'GB', 'TB']):
                    return size

        return None

    def _extract_resolution(self, content: str) -> Optional[str]:
        """æå–åˆ†è¾¨ç‡"""
        resolution_patterns = [
            r'resolution[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'quality[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'åˆ†è¾¨ç‡[\'"]?\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'(\d{3,4}[xÃ—]\d{3,4})',
            r'(\d{3,4}p)',
        ]

        for pattern in resolution_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                resolution = match.group(1).strip()
                if 'x' in resolution or 'p' in resolution:
                    return resolution

        return None
