import requests
import json
import os
import urllib3
import re
from typing import Dict, Any, Optional, List

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


def fetch_posts_from_api(size: int = 50, verify_ssl: bool = False) -> Dict[str, Any]:
    """
    ä»APIæ¥å£è·å–postsæ•°æ®å¹¶ä¿å­˜åˆ°æœ¬åœ°

    Args:
        size (int): æ¯é¡µè¿”å›çš„æ•°æ®æ¡æ•°ï¼Œé»˜è®¤ä¸º50
        verify_ssl (bool): æ˜¯å¦éªŒè¯SSLè¯ä¹¦ï¼Œé»˜è®¤ä¸ºFalse

    Returns:
        Dict[str, Any]: APIè¿”å›çš„JSONæ•°æ®
    """
    # APIæ¥å£URL
    base_url = "https://api.memefans.ai/v2/posts/"

    # å›ºå®šå‚æ•°
    params = {
        "author_id": "BhhLJPlVvjU",
        "page": 1,
        "size": size
    }

    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'application/json',
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1'
    }

    try:
        print(f"æ­£åœ¨è¯·æ±‚API: {base_url}")
        print(f"å‚æ•°: {params}")
        print(f"SSLéªŒè¯: {'å¯ç”¨' if verify_ssl else 'ç¦ç”¨'}")

        # å‘é€GETè¯·æ±‚ï¼Œç¦ç”¨SSLéªŒè¯å¹¶è®¾ç½®è¶…æ—¶
        response = requests.get(
            base_url,
            params=params,
            headers=headers,
            verify=verify_ssl,  # ç¦ç”¨SSLè¯ä¹¦éªŒè¯
            timeout=30  # è®¾ç½®30ç§’è¶…æ—¶
        )
        response.raise_for_status()  # æ£€æŸ¥HTTPé”™è¯¯

        # è§£æJSONæ•°æ®
        data = response.json()

        # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
        output_file = "api_response.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {output_file}")
        print(f"è·å–åˆ° {len(data.get('items', []))} æ¡è®°å½•")

        return data

    except requests.exceptions.SSLError as e:
        print(f"SSLé”™è¯¯: {e}")
        print("å°è¯•ç¦ç”¨SSLéªŒè¯é‡æ–°è¯·æ±‚...")
        if verify_ssl:
            # å¦‚æœä¹‹å‰å¯ç”¨äº†SSLéªŒè¯ï¼Œç°åœ¨ç¦ç”¨é‡è¯•
            return fetch_posts_from_api(size, verify_ssl=False)
        else:
            print("SSLéªŒè¯å·²ç¦ç”¨ï¼Œä½†ä»ç„¶å‡ºç°SSLé”™è¯¯")
            return {}
    except requests.exceptions.RequestException as e:
        print(f"APIè¯·æ±‚å¤±è´¥: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        return {}
    except json.JSONDecodeError as e:
        print(f"JSONè§£æå¤±è´¥: {e}")
        print("å“åº”å†…å®¹å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
        return {}
    except Exception as e:
        print(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        return {}


def read_json_file(file_path: str) -> Dict[str, Any]:
    """
    è¯»å–æœ¬åœ°JSONæ–‡ä»¶

    Args:
        file_path (str): JSONæ–‡ä»¶è·¯å¾„

    Returns:
        Dict[str, Any]: JSONæ•°æ®
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except FileNotFoundError:
        print(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")
        return {}
    except json.JSONDecodeError as e:
        print(f"JSONè§£æå¤±è´¥: {e}")
        return {}
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}


def extract_title_from_description(description: str) -> str:
    """
    ä»descriptionä¸­æå–æ ‡é¢˜å†…å®¹

    Args:
        description (str): å®Œæ•´çš„æè¿°æ–‡æœ¬

    Returns:
        str: æå–çš„æ ‡é¢˜
    """
    if not description:
        return ""

    # æ–¹æ³•1: æå–ã€ã€‘å¼€å¤´åˆ°ç¬¬ä¸€ä¸ª # æˆ–è€…ç‰¹å®šå…³é”®è¯ä¹‹å‰çš„å†…å®¹
    # åŒ¹é…æ¨¡å¼ï¼šã€xxxxã€‘åé¢çš„å†…å®¹ç›´åˆ°é‡åˆ° # æˆ–è€…ç‰¹å®šå…³é”®è¯
    pattern1 = r'ã€[^ã€‘]+ã€‘([^#]+?)(?:\s*#|\s*$)'
    match1 = re.search(pattern1, description)
    if match1:
        title = match1.group(0).strip()
        # ç§»é™¤æœ«å°¾çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        title = re.sub(r'\s*#.*$', '', title).strip()
        return title

    # æ–¹æ³•2: å¦‚æœæ²¡æœ‰ã€ã€‘æ ¼å¼ï¼Œæå–ç¬¬ä¸€ä¸ª#ä¹‹å‰çš„å†…å®¹
    pattern2 = r'^([^#]+?)(?:\s*#|$)'
    match2 = re.search(pattern2, description)
    if match2:
        title = match2.group(1).strip()
        return title

    # æ–¹æ³•3: å¦‚æœéƒ½æ²¡æœ‰åŒ¹é…ï¼Œè¿”å›å‰100ä¸ªå­—ç¬¦
    return description[:100] + "..." if len(description) > 100 else description


def extract_items_data(json_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ä»JSONæ•°æ®ä¸­æå–itemsä¸‹æ¯é¡¹çš„idã€urlã€descriptionã€coverå­—æ®µï¼Œå¹¶æå–æ ‡é¢˜

    Args:
        json_data (Dict[str, Any]): å®Œæ•´çš„JSONæ•°æ®

    Returns:
        List[Dict[str, Any]]: æå–çš„å­—æ®µåˆ—è¡¨
    """
    extracted_items = []

    if 'items' not in json_data:
        print("JSONæ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°'items'å­—æ®µ")
        return extracted_items

    items = json_data['items']

    for item in items:
        # æå–åŸºæœ¬å­—æ®µ
        description = item.get('description', '')

        # æå–æ ‡é¢˜
        title = extract_title_from_description(description)

        extracted_item = {
            'id': item.get('id', ''),
            'url': item.get('url', ''),
            'title': title,  # æ–°å¢æ ‡é¢˜å­—æ®µ
            'description': description,
            'cover': item.get('cover', '')
        }
        extracted_items.append(extracted_item)

    return extracted_items


def save_extracted_data(extracted_data: List[Dict[str, Any]], output_file: str = "extracted_items.json"):
    """
    ä¿å­˜æå–çš„æ•°æ®åˆ°æ–°çš„JSONæ–‡ä»¶

    Args:
        extracted_data (List[Dict[str, Any]]): æå–çš„æ•°æ®
        output_file (str): è¾“å‡ºæ–‡ä»¶å
    """
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(extracted_data, f, ensure_ascii=False, indent=2)
        print(f"æå–çš„æ•°æ®å·²ä¿å­˜åˆ° {output_file}")
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def process_posts_data(data: Dict[str, Any]) -> None:
    """
    å¤„ç†ä»APIè·å–çš„postsæ•°æ®

    Args:
        data (Dict[str, Any]): APIè¿”å›çš„æ•°æ®
    """
    if not data or 'items' not in data:
        print("æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
        return

    items = data['items']
    total = data.get('total', 0)
    page = data.get('page', 1)
    size = data.get('size', 50)

    print(f"\næ•°æ®æ¦‚è§ˆ:")
    print(f"æ€»è®°å½•æ•°: {total}")
    print(f"å½“å‰é¡µ: {page}")
    print(f"æ¯é¡µå¤§å°: {size}")
    print(f"å½“å‰é¡µè®°å½•æ•°: {len(items)}")

    print(f"\nå‰3æ¡è®°å½•çš„æ ‡é¢˜:")
    for i, item in enumerate(items[:3], 1):
        title = item.get('title', 'No title')
        likes = item.get('likes_count', 0)
        comments = item.get('comments_count', 0)
        print(f"{i}. {title} (ğŸ‘{likes} ğŸ’¬{comments})")


def complete_workflow(size: int = 50) -> List[Dict[str, Any]]:
    """
    å®Œæ•´å·¥ä½œæµç¨‹ï¼šä»APIè·å–æ•°æ® -> ä¿å­˜åˆ°æœ¬åœ° -> æå–æŒ‡å®šå­—æ®µ -> ä¿å­˜æå–ç»“æœ

    Args:
        size (int): æ¯é¡µè¿”å›çš„æ•°æ®æ¡æ•°ï¼Œé»˜è®¤ä¸º50

    Returns:
        List[Dict[str, Any]]: æå–çš„å­—æ®µåˆ—è¡¨
    """
    print("=== å¼€å§‹å®Œæ•´å·¥ä½œæµç¨‹ ===")

    # æ­¥éª¤1ï¼šä»APIè·å–æ•°æ®
    print("\næ­¥éª¤1: ä»APIè·å–æ•°æ®...")
    api_data = fetch_posts_from_api(size, verify_ssl=False)  # é»˜è®¤ç¦ç”¨SSLéªŒè¯

    if not api_data:
        print("âŒ ä»APIè·å–æ•°æ®å¤±è´¥ï¼Œå·¥ä½œæµç¨‹ä¸­æ–­")
        return []

    # æ­¥éª¤2ï¼šæ˜¾ç¤ºAPIæ•°æ®æ¦‚è§ˆ
    print("\næ­¥éª¤2: å¤„ç†APIæ•°æ®...")
    process_posts_data(api_data)

    # æ­¥éª¤3ï¼šæå–æŒ‡å®šå­—æ®µ
    print("\næ­¥éª¤3: æå–æŒ‡å®šå­—æ®µ (idã€urlã€titleã€descriptionã€cover)...")
    extracted_items = extract_items_data(api_data)

    if not extracted_items:
        print("âŒ æå–å­—æ®µå¤±è´¥")
        return []

    print(f"âœ… æˆåŠŸæå–äº† {len(extracted_items)} æ¡è®°å½•")

    # æ­¥éª¤4ï¼šä¿å­˜æå–çš„æ•°æ®
    print("\næ­¥éª¤4: ä¿å­˜æå–çš„æ•°æ®...")
    save_extracted_data(extracted_items)

    # æ­¥éª¤5ï¼šæ˜¾ç¤ºæå–ç»“æœé¢„è§ˆ
    print("\næ­¥éª¤5: æ˜¾ç¤ºæå–ç»“æœé¢„è§ˆ...")
    print("å‰5æ¡æå–çš„è®°å½•:")
    for i, item in enumerate(extracted_items[:5], 1):
        print(f"\nè®°å½• {i}:")
        print(f"  ID: {item['id']}")
        print(f"  æ ‡é¢˜: {item['title']}")  # æ˜¾ç¤ºæå–çš„æ ‡é¢˜
        print(f"  URL: {item['url'][:50]}..." if len(item['url']) > 50 else f"  URL: {item['url']}")
        print(f"  å°é¢: {item['cover']}")
        print(f"  å®Œæ•´æè¿°: {item['description'][:150]}..." if len(item['description']) > 150 else f"  å®Œæ•´æè¿°: {item['description']}")

    print("\n=== å®Œæ•´å·¥ä½œæµç¨‹æ‰§è¡Œå®Œæˆ ===")
    return extracted_items


if __name__ == "__main__":
    # é€‰æ‹©æ‰§è¡Œæ¨¡å¼
    print("è¯·é€‰æ‹©æ‰§è¡Œæ¨¡å¼:")
    print("1. å®Œæ•´å·¥ä½œæµç¨‹ (APIè·å– -> æå–å­—æ®µ -> ä¿å­˜)")
    print("2. ä»…ä»æœ¬åœ°JSONæ–‡ä»¶æå–å­—æ®µ")
    print("3. ä»…ä»APIè·å–æ•°æ®")

    mode = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3, é»˜è®¤ä¸º1): ").strip() or "1"

    if mode == "1":
        # å®Œæ•´å·¥ä½œæµç¨‹
        size = input("è¯·è¾“å…¥æ¯é¡µæ•°æ®æ¡æ•° (é»˜è®¤50): ").strip()
        size = int(size) if size.isdigit() else 50

        extracted_items = complete_workflow(size)

        if extracted_items:
            print(f"\nğŸ‰ å·¥ä½œæµç¨‹æˆåŠŸå®Œæˆï¼å…±å¤„ç†äº† {len(extracted_items)} æ¡è®°å½•")
        else:
            print("\nâŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥")

    elif mode == "2":
        # ä»…ä»æœ¬åœ°JSONæ–‡ä»¶æå–å­—æ®µ
        print("\n=== ä»JSONæ–‡ä»¶ä¸­æå–æ•°æ® ===")

        json_file_path = input("è¯·è¾“å…¥JSONæ–‡ä»¶è·¯å¾„ (é»˜è®¤example.json): ").strip() or "example.json"
        json_data = read_json_file(json_file_path)

        if json_data:
            extracted_items = extract_items_data(json_data)

            if extracted_items:
                print(f"æˆåŠŸæå–äº† {len(extracted_items)} æ¡è®°å½•")
                save_extracted_data(extracted_items)

                # æ˜¾ç¤ºå‰5æ¡è®°å½•ä½œä¸ºç¤ºä¾‹
                print("\nå‰5æ¡æå–çš„è®°å½•:")
                for i, item in enumerate(extracted_items[:5], 1):
                    print(f"\nè®°å½• {i}:")
                    print(f"  ID: {item['id']}")
                    print(f"  æ ‡é¢˜: {item['title']}")  # æ˜¾ç¤ºæå–çš„æ ‡é¢˜
                    print(f"  URL: {item['url'][:50]}..." if len(item['url']) > 50 else f"  URL: {item['url']}")
                    print(f"  å°é¢: {item['cover']}")
                    print(f"  å®Œæ•´æè¿°: {item['description'][:150]}..." if len(item['description']) > 150 else f"  å®Œæ•´æè¿°: {item['description']}")
            else:
                print("æ²¡æœ‰æå–åˆ°ä»»ä½•æ•°æ®")
        else:
            print("æ— æ³•è¯»å–JSONæ–‡ä»¶")

    elif mode == "3":
        # ä»…ä»APIè·å–æ•°æ®
        print("\n=== ä»APIè·å–æ•°æ® ===")

        size = input("è¯·è¾“å…¥æ¯é¡µæ•°æ®æ¡æ•° (é»˜è®¤50): ").strip()
        size = int(size) if size.isdigit() else 50

        # è¯¢é—®æ˜¯å¦å¯ç”¨SSLéªŒè¯
        ssl_choice = input("æ˜¯å¦å¯ç”¨SSLè¯ä¹¦éªŒè¯? (y/n, é»˜è®¤n): ").strip().lower()
        verify_ssl = ssl_choice == 'y'

        api_data = fetch_posts_from_api(size, verify_ssl=verify_ssl)

        if api_data:
            process_posts_data(api_data)
            print("âœ… APIæ•°æ®è·å–å®Œæˆ")
        else:
            print("âŒ APIæ•°æ®è·å–å¤±è´¥")

    else:
        print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œç¨‹åºé€€å‡º")
